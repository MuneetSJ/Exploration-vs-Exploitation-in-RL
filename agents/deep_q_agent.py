import os

import numpy as np
import rl.policy

import wandb
from tensorflow.keras.optimizers import Adam
from rl.agents import DQNAgent
from rl.memory import SequentialMemory
from rl.callbacks import WandbLogger
from exploration_policies import *
import cartpole.model as cp
import lunarlander.model as ll
import mountaincar.model as mc


# builds the agent used to train from the actions and model created for the environment

def build_agent(model, actions):
    policy = RandomPolicy()
    memory = SequentialMemory(limit=50000, window_length=1)
    dqn_a = DQNAgent(model=model, memory=memory, policy=policy, nb_actions=actions, nb_steps_warmup=100,
                     target_model_update=1e-2)
    return dqn_a


dqn = build_agent(mc.build_model(mc.states, mc.actions), mc.actions)

dqn.compile(Adam(lr=1e-3), metrics=['mse'])
dqn.fit(mc.env, nb_steps=100000, visualize=False, verbose=1,
        callbacks=[WandbLogger(project='Computing-Project', entity='msjaswal')])
scores = dqn.test(mc.env, nb_episodes=10, visualize=True)
print(np.mean(scores.history['episode_reward']))
