from tensorflow.keras.optimizers import Adam, SGD
from rl.agents import SARSAAgent
from rl.callbacks import WandbLogger
from exploration_policies import *
import cartpole.model as cp
import lunarlander.model as ll
import mountaincar.model as mc
import pendulum.model as pd

# builds the agent used to train from the actions and model created for the environment

def build_agent(model, actions):
    policy = UpperConfidenceBound(2)
    sarsa_a = SARSAAgent(model=model, policy=policy, nb_actions=actions, nb_steps_warmup=100, gamma=.99)
    return sarsa_a


sarsa = build_agent(ll.build_model(ll.states, ll.actions), ll.actions)

sarsa.compile(Adam(lr=1e-3), metrics=['mae'])
sarsa.fit(ll.env, nb_steps=100000, visualize=False, verbose=1,
          callbacks=[WandbLogger(project='Computing-Project', entity='msjaswal')])

scores = sarsa.test(ll.env, nb_episodes=15, visualize=False)
print(np.mean(scores.history['episode_reward']))

